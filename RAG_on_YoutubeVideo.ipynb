{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an Enhanced RAG System to Summarize and Converse with YouTube Videos Using LangChain, Ollama Llama 3.2, and Gradio UI\n",
    "This code implements an interactive YouTube video Q&A system using a combination of tools: Gradio for the user interface, LangChain for managing the retrieval and processing of information, FAISS for efficient vector storage, and Ollama LLaMA for conversational capabilities. Here’s how it works, step by step:\n",
    "\n",
    "## Step-by-Step Code Walkthrough\n",
    "Below libraries are used in this notebook, \n",
    "\n",
    "- Gradio is used to build the interactive UI.\n",
    "- LangChain and HuggingFaceEmbeddings provide tools for processing, embedding, and storing video data.\n",
    "- FAISS is used for efficient similarity-based document retrieval.\n",
    "- RecursiveCharacterTextSplitter helps in splitting the text into manageable chunks.\n",
    "- ChatOllama interfaces with the LLaMA 3.2 model for conversational capabilities.\n",
    "- YoutubeLoader: Extracting text from YouTube video captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "from langchain_ollama import ChatOllama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Processing YouTube URL\n",
    "`process_youtube_url(youtube_url)` function takes a YouTube URL as input and extracts the video transcript using the YoutubeLoader.from_youtube_url method. \n",
    "It then processes the transcript by splitting it into smaller, manageable chunks using the RecursiveCharacterTextSplitter, which divides the text into segments of 512 characters. \n",
    "The resulting chunks are embedded using the HuggingFaceEmbeddings model (specifically, 'all-MiniLM-L6-v2'), which transforms the text into numerical representations suitable for machine learning tasks. These embeddings are then stored in a FAISS vector database, enabling efficient querying and retrieval of information related to the video.\n",
    "Note: In order to modify the code to use captions in a different language, refer to the documentation. By default, the code reads English captions.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Global variable to hold the vector database\n",
    "global_vector_db = None\n",
    "\n",
    "# Function to process the YouTube URL and create the vector store\n",
    "def process_youtube_url(youtube_url):\n",
    "    loader = YoutubeLoader.from_youtube_url(youtube_url, add_video_info=False)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Initialize a text splitter\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=512,\n",
    "        chunk_overlap=256,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \"]\n",
    "    )\n",
    "\n",
    "    # Split the documents and keep metadata\n",
    "    split_docs = splitter.split_documents(documents)\n",
    "\n",
    "    embedding_model = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=embedding_model)\n",
    "\n",
    "    # Ingest into vector database\n",
    "    db = FAISS.from_documents(split_docs, embeddings)\n",
    "    return db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Submitting YouTube URL\n",
    "The `submit_url` function processes the provided YouTube URL by calling the process_youtube_url function to create a vector store from the video's transcript. After processing, it uses a default question (\"Summarize this video\") to initiate a retrieval-based question-answering process. If successful, it returns a status message indicating the video has been indexed successfully, along with a summary. In case of an error, the function catches exceptions and returns an error message, ensuring a smooth user experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to answer questions based on the vector store and chat history\n",
    "# Submit URL function\n",
    "def submit_url(youtube_url):\n",
    "    global global_vector_db\n",
    "    try:\n",
    "        # Process the YouTube URL\n",
    "        global_vector_db = process_youtube_url(youtube_url)\n",
    "        \n",
    "        # Default question for summarization\n",
    "        default_question = \"Summarize this video.\"\n",
    "        chat_history = []  # Empty chat history for the first question\n",
    "        \n",
    "        # Get the summary\n",
    "        summary, _ = answer_question(default_question, chat_history)\n",
    "        \n",
    "        # Status message\n",
    "        status_message = \"Video indexed successfully ✅! You can now ask questions about the video in the chatbot.\"\n",
    "    except Exception as e:\n",
    "        # Handle errors and display in the status box\n",
    "        status_message = f\"❌ Error processing the video: {str(e)}\"\n",
    "        summary = \"\"  # No summary in case of error\n",
    "    \n",
    "    # Return the status message and the summary\n",
    "    return status_message, summary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Answering Questions Based on the Video\n",
    "The `answer_question` function answers user questions based on the video's indexed content. It first checks if the vector database is available; if not, it prompts the user to process a video. Then, it uses the ChatOllama model and a retrieval chain to search for relevant information in the vector database and generate a concise answer. The question and corresponding answer are appended to the chat_history, allowing for a continuous, interactive conversation. If an error occurs, the function handles it by appending the error message to the chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def answer_question(question, chat_history):\n",
    "    global global_vector_db\n",
    "    if global_vector_db is None:\n",
    "        return \"Please process a YouTube video URL first.\", chat_history\n",
    "\n",
    "    try:\n",
    "        local_llm = 'llama3.2'\n",
    "        llama3 = ChatOllama(model=local_llm, temperature=0)\n",
    "\n",
    "        retriever = global_vector_db.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "        system_prompt = (\n",
    "            \"You are a video assistant tasked with answering questions based on the provided YouTube video context. \"\n",
    "            \"Use the given context to provide accurate, concise answers in three sentences. \"\n",
    "            \"If the context does not contain the answer, say you are not sure \"\n",
    "            \"Context: {context}\"\n",
    "        )\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system_prompt),\n",
    "                (\"human\", \"{input}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        question_answer_chain = create_stuff_documents_chain(llama3, prompt)\n",
    "        chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "        response = chain.invoke({\"input\": question})\n",
    "        \n",
    "        # Ensure the response contains the expected \"answer\" key\n",
    "        if \"answer\" not in response:\n",
    "            raise ValueError(\"Response does not contain an 'answer' key.\")\n",
    "        \n",
    "        # Append the question and answer to chat history as a tuple\n",
    "        chat_history.append((question, response['answer']))\n",
    "        \n",
    "        # Return the answer and updated chat history\n",
    "        return response['answer'], chat_history\n",
    "    except Exception as e:\n",
    "        # Return error message in case of failure\n",
    "        error_message = f\"Error: {str(e)}\"\n",
    "        chat_history.append((question, error_message))\n",
    "        return error_message, chat_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Asking Questions via Gradio\n",
    "The `ask_question` function interacts with the user to answer their query. It calls the answer_question function, passing the question and the current chat_history to retrieve an answer. The updated chat history, which includes the user's question and the assistant's response, is returned, allowing the conversation to continue smoothly. This function ensures a seamless Q&A interaction with the chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gradio interface function to ask a question\n",
    "def ask_question(question, chat_history):\n",
    "    response, updated_chat_history = answer_question(question, chat_history)\n",
    "    return updated_chat_history, updated_chat_history  # Return the updated chat history for gr.Chatbot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Creating Gradio Interface\n",
    "`create_gradio_interface()` function constructs the Gradio interface, providing a user-friendly layout for interaction with the system. It includes input fields for users to enter a YouTube URL and ask questions about the video. The interface features a submission button, status information box, and a summary box to display the video summary. Users can also ask questions, view responses, and clear the chat history as needed. Additionally, the interface includes a footer for supplementary information. This function defines the overall structure and interaction flow of the application, making it accessible and intuitive for users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_gradio_interface():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"<h1 style='text-align: center; color: #4A90E2;'>YouTube Video Q&A</h1>\")\n",
    "        gr.Markdown(\"<p style='text-align: center;'>Enter a YouTube video URL to extract information and ask questions about it.</p>\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                youtube_url = gr.Textbox(label=\"YouTube Video URL\", placeholder=\"Enter the YouTube video URL here...\", lines=1)\n",
    "                submit_btn = gr.Button(\"Submit URL\", variant=\"primary\")\n",
    "                \n",
    "                # Status box for indexing completion or error messages\n",
    "                status_info = gr.Textbox(\n",
    "                    label=\"Status Info\", \n",
    "                    placeholder=\"Indexing status will appear here...\", \n",
    "                    interactive=False, \n",
    "                    lines=2\n",
    "                )\n",
    "\n",
    "                # Summary box for video summary\n",
    "                summary_box = gr.Textbox(\n",
    "                    label=\"Video Summary\", \n",
    "                    placeholder=\"Summary will appear here...\", \n",
    "                    interactive=False, \n",
    "                    lines=6\n",
    "                )\n",
    "                \n",
    "                # Link submit button to the submit_url function\n",
    "                submit_btn.click(fn=submit_url, inputs=youtube_url, outputs=[status_info, summary_box])\n",
    "\n",
    "            with gr.Column(scale=1):\n",
    "                chat_history = gr.Chatbot()\n",
    "                question = gr.Textbox(label=\"Your Question\", placeholder=\"Ask a question about the video...\", lines=1)\n",
    "                ask_btn = gr.Button(\"Ask Question\", variant=\"primary\")\n",
    "                clear_btn = gr.Button(\"Clear Chat\", variant=\"secondary\")\n",
    "                state = gr.State([])\n",
    "\n",
    "                # Link ask button to the ask_question function\n",
    "                ask_btn.click(fn=ask_question, inputs=[question, state], outputs=[chat_history, state])\n",
    "                \n",
    "                # Clear chat history\n",
    "                clear_btn.click(fn=lambda: ([], []), inputs=[], outputs=[chat_history, state])  # Clear chat history\n",
    "\n",
    "        # Add a footer or additional information\n",
    "        gr.Markdown(\"<footer style='text-align: center; margin-top: 20px;'>© Vikram Bhat</footer>\")\n",
    "\n",
    "    return demo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Launching the Gradio Interface\n",
    "`interface.launch` starts the Gradio interface, allowing users to interact with the system by entering a YouTube URL, asking questions, and receiving answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the Gradio interface\n",
    "interface = create_gradio_interface()\n",
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Enter the enhanced Retrieval-Augmented Generation (RAG) system. By integrating cutting-edge tools like LangChain, Ollama Llama 3.2, and Gradio UI, this application takes video summarization and Q&A to the next level. \n",
    "The RAG system is designed to not only summarize YouTube videos using the captions but also enable interactive conversations with the content, allowing users to ask questions and receive precise, contextually relevant answers in real-time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
